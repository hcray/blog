---
layout: post
title: ELK搭建
category: ELK
description: ELK搭建
keywords: ELK,linux
---
<p>ELK搭建</p>
<pre>
1、elasticSearch
groupadd elsearch                   #新建elsearch组
useradd elsearch -g elsearch -p elasticsearch  #新建一个elsearch用户
chown -R elsearch:elsearch  ./elasticsearch    #指定elasticsearch所属elsearch组


1、启动 elasticsearch 如出现异常  can not run elasticsearch as root
解决方法：创建ES 账户，修改文件夹 文件 所属用户 组
2、启动异常：ERROR: bootstrap checks failed
system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk
问题原因：因为Centos6不支持SecComp，而ES5.2.1默认bootstrap.system_call_filter为true进行检测，所以导致检测失败，失败后直接导致ES不能启动。详见 ：https://github.com/elastic/elasticsearch/issues/22899
解决方法：在elasticsearch.yml中配置bootstrap.system_call_filter为false，注意要在Memory下面:
bootstrap.memory_lock: false
bootstrap.system_call_filter: false
3、启动后，如果只有本地可以访问，尝试修改配置文件 elasticsearch.yml
中network.host(注意配置文件格式不是以 # 开头的要空一格， ： 后要空一格)
为 network.host: 0.0.0.0
默认端口是 9200
注意：关闭防火墙 或者开放9200端口
4、ERROR: bootstrap checks failed
max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]
max number of threads [1024] for user [lishang] likely too low, increase to at least [2048]
解决方法：切换到root用户，编辑limits.conf 添加类似如下内容
vi /etc/security/limits.conf
添加如下内容:
* soft nofile 65536
* hard nofile 131072
* soft nproc 2048
* hard nproc 4096
5、max number of threads [1024] for user [lish] likely too low, increase to at least [2048]
解决：切换到root用户，进入limits.d目录下修改配置文件。
vi /etc/security/limits.d/90-nproc.conf
修改如下内容：
* soft nproc 1024
#修改为
* soft nproc 2048
6、max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144]
解决：切换到root用户修改配置sysctl.conf
vi /etc/sysctl.conf
添加下面配置：
vm.max_map_count=655360
并执行命令：
sysctl -p
然后，重新启动elasticsearch，即可启动成功。





解压完之后，我们到config目录中新建一个logstash.conf配置。
input {
     file {
        type => "log"
        path => "/var/log/vmp/*.log"
        start_position => "beginning"
    }
}
output {
  stdout {
   codec => rubydebug { }
  }
  elasticsearch {
    hosts => "10.1.1.118"
    index => "log-%{+YYYY.MM.dd}"
  }
}
  然后做好input ，filter，output三大块， 其中input是吸取logs文件下的所有log后缀的日志文件，filter是一个过滤函数，这里不用配置，output配置了导入到
hosts为127.0.0.1:9200的elasticsearch中，每天一个索引。
./logstash -f ../config/logstash.conf

nohup ./logstash -f ../config/logstash.conf & >/dev/null

jdk单独配置版本
2、vi /etc/sysconfig/logstash，新增 JAVA_HOME=/usr/java/jdk1.8.0_131
3、vi /opt/logstash/bin/logstash.lib.sh ，在页首新增export JAVA_HOME=/usr/java/jdk1.8.0_131








4. kibana
    它的配置也非常简单，你需要在kibana.yml文件中指定一下你需要读取的elasticSearch地址和可供外网访问的bind地址就可以了。



[root@slave1 config]# pwd
/usr/myapp/kibana/config

[root@slave1 config]# vim kibana.yml

elasticsearch.url: "http://localhost:9200";
server.host: 0.0.0.0


      然后就是启动，从日志中可以看出，当前开了5601端口。





部署 Filebeat



[plain] view plain copy
	1.
# tar zxvf filebeat-5.0.0-linux-x86.tar.gz
	2.
# mv filebeat-5.0.0-linux-x86  /usr/local/elasticsearch/files/filebeat
	3.
# cd /usr/local/elasticsearch/files/filebeat



方法一： 配置输出到 elasticsearch
以下为默认设置,即把文件（/var/log/*.log）输出到 elasticsearch



[plain] view plain copy
	1.
# vi filebeat.yml
	2.
filebeat.prospectors:
	3.
- input_type: log
	4.
  paths:
	5.
  - /var/log/*.log
	6.

	7.
output.elasticsearch:
	8.
  hosts: ["localhost:9200"]


把配置改为如下，只读取mysql日志，直接输出到 elasticsearch，同时添加模板



[plain] view plain copy
	1.
filebeat.prospectors:
	2.
- input_type: log
	3.
  paths:
	4.
    - /var/log/mysqld.log
	5.

	6.
output.elasticsearch:
	7.
  hosts: ["192.168.1.222:9200"]
	8.
  template.name: "filebeat"
	9.
  template.path: "filebeat.template.json"
	10.
  template.overwrite: false



启动 filebeat



[sql] view plain copy
	1.
./filebeat start


service filebeat start

打开kibana地址 http://192.168.1.222:5601/ ，创建以下索引匹配模式： filebeat-*


查询 filebeat-* ，数据已经过来了。




方法二： 配置输出到 logstash

logstash 可以统一筛选匹配有用的数据，也可输出到多个目标
需要配置 logstash 到 elasticsearch 的输出输入，再配置 filebeat 到 logstash 的输出输入
参考：  Elasticsearch 入门：logstash 5.0.0 安装及输出数据到 elasticsearch


配置filebeat 的输入为redis日志，输出 logstash （注意：先注释方法一的配置）



[plain] view plain copy
	1.
# vi filebeat.yml
	2.

	3.
filebeat.prospectors:
	4.
-
	5.
  input_type: log
	6.
  paths:
	7.
    - /var/log/redis_6380.log
	8.
  output.logstash:
	9.
    hosts: ["192.168.1.222:5044"]



编辑 logstash 配置文件，配置 logstash 的输入和输出



[plain] view plain copy
	1.
# vi config/logstashtest.conf
	2.
input {
	3.
    beats {
	4.
        port => 5044
	5.
    }
	6.
}
	7.
output{
	8.
    elasticsearch {
	9.
        hosts => ["192.168.1.222:9200"]
	10.
        index => "test"
	11.
    }
	12.
}



重启 logstas



[plain] view plain copy
	1.
bin/logstash -f config/logstashtest.conf


检查配置是否正确



[plain] view plain copy
	1.
./filebeat -configtest -e



重启 filebeat



[plain] view plain copy
	1.
./filebeat start



打开kibana地址 http://192.168.1.222:5601/ ，默认索引test


</pre>